proxy_cache_path /var/www/docker-registry-cache levels=1:2 inactive=60d max_size=32g keys_zone=cache:10m use_temp_path=off;
server {
    listen 5050;

    resolver 8.8.8.8 4.2.2.2 ipv6=off;

    # Docker needs this. Don't ask.
    chunked_transfer_encoding on;

    proxy_read_timeout 900;

    proxy_max_temp_file_size 0;
    proxy_request_buffering off;
    proxy_http_version 1.1;

    # Use cache locking, with a huge timeout, so that multiple Docker clients asking for the same blob at the same time
    # will wait for the first to finish instead of doing multiple upstream requests.
    proxy_cache_lock on;
    proxy_cache_lock_timeout 880s;

    # Cache all 200, 206 for 60 days.
    proxy_cache_valid 200 206 60d;

    # Some extra settings to maximize cache hits and efficiency
    proxy_force_ranges on;
    proxy_ignore_client_abort on;
    proxy_cache_revalidate on;

    # Hide/ignore headers from caching. S3 especially likes to send Expires headers in the past in some situations.
    proxy_hide_header      Set-Cookie;
    proxy_ignore_headers   X-Accel-Expires Expires Cache-Control Set-Cookie;

    # Use SNI during the TLS handshake with the upstream.
    proxy_ssl_server_name on;

    # Block API v1. We dont know how to handle these.
    # Docker-client should start with v2 and fallback to v1 if something fails, for example, if authentication failed to a protected v2 resource.
    location /v1 {
        return 405 "docker-registry-proxy: docker is trying to use v1 API. Either the image does not exist upstream, or you need to configure docker-registry-proxy to authenticate against $host";
    }

    # For blob requests by digest, do cache, and treat redirects.
    location ~ ^/v2/(.*)/blobs/sha256:(.*) {
        proxy_pass https://registry.hub.docker.com;
        proxy_cache cache;
        proxy_cache_key   $uri;
        proxy_intercept_errors on;
        error_page 301 302 307 = @handle_redirects;
    }

    # For manifest requests by digest, do cache, and treat redirects.
    # These are some of the requests that DockerHub will throttle.
    location ~ ^/v2/(.*)/manifests/sha256:(.*) {
        proxy_pass https://registry.hub.docker.com;
        proxy_cache cache;
        proxy_cache_key $uri;
        proxy_intercept_errors on;
        error_page 301 302 307 = @handle_redirects;
    }

    # Cache blobs requests that are not by digest
    # Since these are mutable, we invalidate them immediately and keep them only in case the backend is down
    location ~ ^/v2/(.*)/blobs/ {
        proxy_cache_valid 0s;
        proxy_pass https://registry.hub.docker.com;
        proxy_cache cache;
        proxy_cache_key $uri;
        proxy_intercept_errors on;
        error_page 301 302 307 = @handle_redirects;
        proxy_cache_use_stale  error timeout http_500 http_502 http_504 http_429;
    }

    location @handle_redirects {
        #store the current state of the world so we can reuse it in a minute
        # We need to capture these values now, because as soon as we invoke
        # the proxy_* directives, these will disappear
        set $original_uri $uri;
        set $orig_loc $upstream_http_location;

        # during this process, nginx will preserve the headers intended for the original destination.
        # in most cases thats okay, but for some (eg: google storage), passing an Authorization
        # header can cause problems. Also, that would leak the credentials for the registry
        # into the storage system (unrelated).
        proxy_set_header      Authorization "";

        # nginx goes to fetch the value from the upstream Location header
        proxy_pass $orig_loc;
        proxy_cache cache;
        # But we store the result with the cache key of the original request URI
        # so that future clients don't need to follow the redirect too
        proxy_cache_key $original_uri;
    }

    # by default, dont cache anything.
    location / {
        proxy_pass https://registry.hub.docker.com;
        proxy_cache off;
    }
}




